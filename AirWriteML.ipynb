{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtA5DK3E9bzK"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/TusharW4ni/AirWriteML.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnzBupOL98f5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df[['index', 'x', 'y', 'z']].values\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    return X\n",
        "\n",
        "letter_samples = {\n",
        "    'A': [load(f'./AirWriteML/data/A/A_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'B': [load(f'./AirWriteML/data/B/B_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'C': [load(f'./AirWriteML/data/C/C_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'D': [load(f'./AirWriteML/data/D/D_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'E': [load(f'./AirWriteML/data/E/E_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'H': [load(f'./AirWriteML/data/H/H_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'I': [load(f'./AirWriteML/data/I/I_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'L': [load(f'./AirWriteML/data/L/L_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'N': [load(f'./AirWriteML/data/N/N_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'O': [load(f'./AirWriteML/data/O/O_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'R': [load(f'./AirWriteML/data/R/R_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'S': [load(f'./AirWriteML/data/S/S_sample_{i}.csv') for i in range(1, 51)],\n",
        "    'T': [load(f'./AirWriteML/data/T/T_sample_{i}.csv') for i in range(1, 51)],\n",
        "}\n",
        "\n",
        "max_length = max(len(sample) for samples in letter_samples.values() for sample in samples)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for label, samples in letter_samples.items():\n",
        "    for sample in samples:\n",
        "        padded_sample = np.pad(sample, ((0, max_length - len(sample)), (0, 0)), 'constant')\n",
        "        X.append(padded_sample)\n",
        "        y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "label_to_index = {label: index for index, label in enumerate(sorted(set(y)))}\n",
        "y_numeric = np.array([label_to_index[label] for label in y])\n",
        "\n",
        "y_onehot = to_categorical(y_numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWST_x0Y_Mhh"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, num_classes):\n",
        "  model = Sequential([\n",
        "      Input(shape=input_shape),\n",
        "      LSTM(64, return_sequences=True),\n",
        "      LSTM(32),\n",
        "      Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDGe86Ky_O86"
      },
      "outputs": [],
      "source": [
        "# KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "num_classes = len(label_to_index)\n",
        "\n",
        "fold_no = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y_onehot[train_index], y_onehot[test_index]\n",
        "    print(X.shape[1])\n",
        "    print(X.shape[2])\n",
        "    model = create_model((X.shape[1], X.shape[2]), num_classes)\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        batch_size=32,\n",
        "                        epochs=200,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Plotting the graphs for each fold\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Fold {fold_no} - Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Fold {fold_no} - Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "model.save('air_write_model.h5')\n",
        "import json\n",
        "with open('label_to_index.json', 'w') as f:\n",
        "    json.dump(label_to_index, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjHweO1o_oBi"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=sorted(label_to_index.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=sorted(label_to_index.keys()), yticklabels=sorted(label_to_index.keys()))\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bR3EchhGgcDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGgoNuys58nn"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNvP3Ewt_0GX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_model(input_shape, num_classes):\n",
        "  model = Sequential([\n",
        "      Input(shape=input_shape),\n",
        "      LSTM(64, return_sequences=True),\n",
        "      LSTM(32),\n",
        "      Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def load_and_preprocess(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    X = df[['index', 'x', 'y', 'z']].values\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    return X\n",
        "\n",
        "def predict_letter(model, file_path, max_length, label_to_index):\n",
        "    X = load_and_preprocess(file_path)\n",
        "\n",
        "    if len(X) < max_length:\n",
        "        padded_sample = np.pad(X, ((0, max_length - len(X)), (0, 0)), 'constant')\n",
        "    else:\n",
        "        padded_sample = X[:max_length]\n",
        "\n",
        "    padded_sample = np.expand_dims(padded_sample, axis=0)\n",
        "\n",
        "    pred = model.predict(padded_sample)\n",
        "    pred_class = np.argmax(pred, axis=1)[0]\n",
        "\n",
        "    return list(label_to_index.keys())[pred_class]\n",
        "\n",
        "input_shape = (max_length, X.shape[2])\n",
        "num_classes = len(label_to_index)\n",
        "model = create_model(input_shape, num_classes)\n",
        "model.load_weights('air_write_model.h5')\n",
        "\n",
        "file_path = 'file.csv'\n",
        "predicted_letter = predict_letter(model, file_path, max_length, label_to_index)\n",
        "\n",
        "print(f\"Predicted Letter: {predicted_letter}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}